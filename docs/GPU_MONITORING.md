# GPU Resource Monitoring for VERL Training

ì´ ë¬¸ì„œëŠ” VERL í›ˆë ¨ ì¤‘ GPU ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³  WandBì—ì„œ ì‹œê°í™”í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
pip install pynvml psutil wandb
```

### 2. GRPO í›ˆë ¨ì—ì„œ GPU ëª¨ë‹ˆí„°ë§ í™œì„±í™”

ê¸°ì¡´ GRPO í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ì— ë‹¤ìŒ ì˜µì…˜ì„ ì¶”ê°€í•˜ì„¸ìš”:

```bash
python3 -m verl.trainer.main_ppo \
    # ... ê¸°ì¡´ ì„¤ì •ë“¤ ... \
    +trainer.enable_gpu_monitoring=true \
    +trainer.gpu_monitor_interval=2.0
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§ë˜ëŠ” ë©”íŠ¸ë¦­

### GPU ë©”íŠ¸ë¦­ (ê° GPUë³„)
- **GPU ì‚¬ìš©ë¥ ** (`gpu_N_gpu_utilization_pct`): GPU ì½”ì–´ ì‚¬ìš©ë¥  (%)
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ** (`gpu_N_memory_utilization_pct`): GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  (%)
- **ë©”ëª¨ë¦¬ í• ë‹¹ëŸ‰** (`gpu_N_memory_allocated_gb`): PyTorchê°€ í• ë‹¹í•œ ë©”ëª¨ë¦¬ (GB)
- **ë©”ëª¨ë¦¬ ì˜ˆì•½ëŸ‰** (`gpu_N_memory_reserved_gb`): PyTorchê°€ ì˜ˆì•½í•œ ë©”ëª¨ë¦¬ (GB)
- **ì´ ë©”ëª¨ë¦¬** (`gpu_N_memory_total_gb`): GPU ì´ ë©”ëª¨ë¦¬ (GB)
- **ì˜¨ë„** (`gpu_N_temperature_c`): GPU ì˜¨ë„ (Â°C)
- **ì „ë ¥ ì‚¬ìš©ëŸ‰** (`gpu_N_power_usage_w`): ì „ë ¥ ì†Œë¹„ëŸ‰ (W)
- **í´ëŸ­ ì†ë„** (`gpu_N_graphics_clock_mhz`, `gpu_N_memory_clock_mhz`): GPU/ë©”ëª¨ë¦¬ í´ëŸ­ (MHz)

### ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
- **CPU ì‚¬ìš©ë¥ ** (`cpu_utilization_pct`): CPU ì‚¬ìš©ë¥  (%)
- **ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬** (`system_memory_used_gb`, `system_memory_utilization_pct`): ì‹œìŠ¤í…œ RAM ì‚¬ìš©ëŸ‰

## ğŸ› ï¸ ì‚¬ìš© ë°©ë²•

### ë°©ë²• 1: í›ˆë ¨ê³¼ í†µí•©ëœ ëª¨ë‹ˆí„°ë§ (ê¶Œì¥)

GRPO í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ì— GPU ëª¨ë‹ˆí„°ë§ì„ í†µí•©:

```bash
python3 -m verl.trainer.main_ppo \
    algorithm.adv_estimator=grpo \
    # ... ê¸°íƒ€ ì„¤ì • ... \
    trainer.logger='["console","wandb"]' \
    trainer.project_name='your_project' \
    trainer.experiment_name='your_experiment' \
    +trainer.enable_gpu_monitoring=true \
    +trainer.gpu_monitor_interval=1.0
```

**ì„¤ì • ì˜µì…˜:**
- `trainer.enable_gpu_monitoring`: GPU ëª¨ë‹ˆí„°ë§ í™œì„±í™” (ê¸°ë³¸ê°’: false)
- `trainer.gpu_monitor_interval`: ëª¨ë‹ˆí„°ë§ ê°„ê²© (ì´ˆ, ê¸°ë³¸ê°’: 1.0)

### ë°©ë²• 2: ë…ë¦½ì ì¸ GPU ëª¨ë‹ˆí„°ë§

í›ˆë ¨ê³¼ ë³„ë„ë¡œ GPU ëª¨ë‹ˆí„°ë§ë§Œ ì‹¤í–‰:

```bash
# ê¸°ë³¸ ëª¨ë‹ˆí„°ë§ (ì½˜ì†” ì¶œë ¥ë§Œ)
python scripts/monitor_gpu_realtime.py

# WandBì™€ í•¨ê»˜ ëª¨ë‹ˆí„°ë§
python scripts/monitor_gpu_realtime.py \
    --wandb-project "gpu_monitoring" \
    --wandb-run-name "training_session_1" \
    --interval 0.5

# íŠ¹ì • GPUë§Œ ëª¨ë‹ˆí„°ë§
python scripts/monitor_gpu_realtime.py \
    --gpus "0,1,2,3" \
    --interval 2.0 \
    --wandb-project "gpu_monitoring"

# ì½˜ì†” ì¶œë ¥ ì—†ì´ WandBë§Œ
python scripts/monitor_gpu_realtime.py \
    --wandb-project "gpu_monitoring" \
    --no-console
```

**ë…ë¦½ ëª¨ë‹ˆí„°ë§ ì˜µì…˜:**
- `--interval`: ëª¨ë‹ˆí„°ë§ ê°„ê²© (ì´ˆ)
- `--wandb-project`: WandB í”„ë¡œì íŠ¸ ì´ë¦„
- `--wandb-run-name`: WandB ì‹¤í–‰ ì´ë¦„
- `--gpus`: ëª¨ë‹ˆí„°ë§í•  GPU ID (ì‰¼í‘œë¡œ êµ¬ë¶„)
- `--no-console`: ì½˜ì†” ì¶œë ¥ ë¹„í™œì„±í™”
- `--summary-interval`: ìš”ì•½ ì¶œë ¥ ê°„ê²© (ì´ˆ)

## ğŸ“ˆ WandBì—ì„œ ì‹œê°í™”

WandB ëŒ€ì‹œë³´ë“œì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ ì°¨íŠ¸ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

### 1. GPU ì‚¬ìš©ë¥  ì°¨íŠ¸
```
Yì¶•: gpu_0_gpu_utilization_pct, gpu_1_gpu_utilization_pct, ...
Xì¶•: Step
```

### 2. GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì°¨íŠ¸
```
Yì¶•: gpu_0_memory_allocated_gb, gpu_0_memory_total_gb
Xì¶•: Step
```

### 3. GPU ì˜¨ë„ ëª¨ë‹ˆí„°ë§
```
Yì¶•: gpu_0_temperature_c, gpu_1_temperature_c, ...
Xì¶•: Step
```

### 4. ì „ë ¥ ì†Œë¹„ëŸ‰ ì¶”ì 
```
Yì¶•: gpu_0_power_usage_w, gpu_1_power_usage_w, ...
Xì¶•: Step
```

## ğŸ”§ ê³ ê¸‰ ì‚¬ìš©ë²•

### ì»¤ìŠ¤í…€ ëª¨ë‹ˆí„°ë§ êµ¬í˜„

```python
from verl.utils.gpu_monitor import GPUResourceMonitor

# ì»¤ìŠ¤í…€ ëª¨ë‹ˆí„° ìƒì„±
monitor = GPUResourceMonitor(
    monitor_interval=0.5,  # 0.5ì´ˆë§ˆë‹¤ ëª¨ë‹ˆí„°ë§
    log_to_wandb=True,
    log_to_console=True,
    device_ids=[0, 1, 2, 3]  # íŠ¹ì • GPUë§Œ ëª¨ë‹ˆí„°ë§
)

# ëª¨ë‹ˆí„°ë§ ì‹œì‘
monitor.start_monitoring()

# ìµœì‹  ë©”íŠ¸ë¦­ ê°€ì ¸ì˜¤ê¸°
latest_metrics = monitor.get_latest_metrics()
print(f"GPU 0 ì‚¬ìš©ë¥ : {latest_metrics['gpu_0_gpu_utilization_pct']:.1f}%")

# ëª¨ë‹ˆí„°ë§ ì¤‘ì§€
monitor.stop_monitoring()
```

### ê¸°ì¡´ ì½”ë“œì— í†µí•©

```python
from verl.utils.tracking import Tracking

# GPU ëª¨ë‹ˆí„°ë§ì´ í™œì„±í™”ëœ Tracking ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
logger = Tracking(
    project_name="my_project",
    experiment_name="my_experiment", 
    default_backend=["wandb"],
    enable_gpu_monitoring=True,
    gpu_monitor_interval=1.0
)

# ì´í›„ logger.log() í˜¸ì¶œ ì‹œ GPU ë©”íŠ¸ë¦­ë„ ìë™ìœ¼ë¡œ ë¡œê¹…ë¨
```

## ğŸš¨ ì£¼ì˜ì‚¬í•­

1. **ì„±ëŠ¥ ì˜í–¥**: ëª¨ë‹ˆí„°ë§ ê°„ê²©ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ (< 0.5ì´ˆ) í›ˆë ¨ ì„±ëŠ¥ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

2. **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: ì¥ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œ ë©”íŠ¸ë¦­ íˆìŠ¤í† ë¦¬ê°€ ë©”ëª¨ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

3. **ê¶Œí•œ**: NVML ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ ì ì ˆí•œ GPU ë“œë¼ì´ë²„ì™€ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.

4. **ì˜ì¡´ì„±**: 
   - `pynvml`: NVIDIA GPU ì„¸ë¶€ ì •ë³´ (ì˜¨ë„, ì „ë ¥ ë“±)
   - `psutil`: ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì •ë³´
   - `wandb`: WandB ë¡œê¹… (ì„ íƒì‚¬í•­)

## ğŸ› ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

1. **NVML ì´ˆê¸°í™” ì‹¤íŒ¨**
   ```bash
   pip install pynvml
   # ë˜ëŠ” NVIDIA ë“œë¼ì´ë²„ ì—…ë°ì´íŠ¸
   ```

2. **WandB ë¡œê·¸ì¸ ë¬¸ì œ**
   ```bash
   wandb login
   ```

3. **ê¶Œí•œ ë¬¸ì œ**
   ```bash
   # Docker í™˜ê²½ì—ì„œëŠ” --gpus all ì˜µì…˜ í•„ìš”
   docker run --gpus all ...
   ```

4. **ë©”ëª¨ë¦¬ ë¶€ì¡±**
   - ëª¨ë‹ˆí„°ë§ ê°„ê²©ì„ ëŠ˜ë¦¬ê±°ë‚˜ (`gpu_monitor_interval` ì¦ê°€)
   - ë©”íŠ¸ë¦­ íˆìŠ¤í† ë¦¬ ì œí•œ ì„¤ì •

## ğŸ“ ì˜ˆì œ ì¶œë ¥

ì½˜ì†” ì¶œë ¥ ì˜ˆì œ:
```
ğŸš€ Starting GPU monitoring...
ğŸ“Š Monitoring interval: 1.0s
ğŸ–¥ï¸  Monitoring GPUs: [0, 1, 2, 3, 4, 5, 6, 7]
ğŸ“ˆ WandB logging: âœ“
ğŸ–¨ï¸  Console output: âœ“

GPU Monitor - GPU0: 85.2%/76.3% | GPU1: 82.1%/74.8% | GPU2: 88.5%/78.2% | GPU3: 84.7%/75.9%
```

WandB ëŒ€ì‹œë³´ë“œì—ì„œëŠ” ì‹¤ì‹œê°„ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ëŠ” ì°¨íŠ¸ë“¤ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
